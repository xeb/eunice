# Eunice v1.0.1

An agentic CLI runner in Rust with unified support for OpenAI, Gemini, Claude, Azure OpenAI, and Ollama.

## Overview

Eunice is a command-line tool that provides an AI assistant with 4 built-in tools: Bash, Read, Write, and Skill. It emphasizes "sophisticated simplicity" - minimal configuration with maximum capability.

## Installation

```bash
cargo install --git ssh://git@github.com/xeb/eunice.git
```

Or from source:

```bash
git clone git@github.com:xeb/eunice.git
cd eunice
cargo install --path .
```

## Quick Start

```bash
# Set your API key
export GEMINI_API_KEY=your_key_here
# or
export OPENAI_API_KEY=your_key_here
# or
export ANTHROPIC_API_KEY=your_key_here

# Run with a prompt
eunice "List all files in the current directory"

# Interactive chat mode
eunice --chat

# Use a specific model
eunice --model flash "Hello"
eunice --model sonnet "Explain this code"
eunice --model azure:gpt-4o-mini "Hello from Azure"
```

## Built-in Tools

Eunice provides 4 built-in tools that are always available:

### Bash
Execute shell commands. Returns stdout, stderr, and exit code.

### Read
Read file contents. Returns file content or error if file doesn't exist.

### Write
Write content to a file. Creates parent directories if needed.

### Skill
Discover and describe available skills. Skills are user-defined prompts stored in ~/.eunice/skills/.

## Skills System

Skills are reusable prompts stored in `~/.eunice/skills/<skill-name>/SKILL.md`. Each skill file must have a `## Description` section.

### Default Skills

Eunice includes default skills that are auto-installed on first run:
- **image_analysis**: Analyze images using multimodal AI
- **web_search**: Search the web for information
- **git_helper**: Git operations and best practices

### Creating Custom Skills

```bash
mkdir -p ~/.eunice/skills/my_skill
cat > ~/.eunice/skills/my_skill/SKILL.md << 'EOF'
# My Custom Skill

## Description
A helpful skill that does something useful.

## Instructions
When invoked, do the following...
EOF
```

## Supported Providers

### Google Gemini (Default)
Set `GEMINI_API_KEY`. Default model: `gemini-3-flash-preview`
Aliases: `flash` -> gemini-3-flash-preview, `pro` -> gemini-3-pro-preview

### OpenAI
Set `OPENAI_API_KEY`. Models: gpt-4o, gpt-4o-mini, o1, o3, etc.

### Anthropic Claude
Set `ANTHROPIC_API_KEY`. Models: claude-sonnet-4, claude-opus-4, etc.
Aliases: `sonnet`, `opus`, `haiku`

### Azure OpenAI
Set `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_API_KEY`.
Optional: `AZURE_OPENAI_API_VERSION` (default: 2024-02-01)
Usage: `--model azure:<deployment-name>`

### Ollama (Local)
Runs against localhost:11434. Tool-capable models: llama3.1, llama3.2, qwen2.5, qwen3, glm, deepseek, mistral-nemo, etc.

## CLI Reference

```
eunice [OPTIONS] [PROMPT]

Arguments:
  [PROMPT]  The prompt to send to the AI

Options:
      --model <MODEL>   AI model to use
      --prompt <TEXT>   System prompt (inline text or file path)
      --chat            Interactive chat mode
      --webapp          Start web server interface
      --list-models     List available AI models
      --list-tools      List the 4 built-in tools
      --llms-txt        Output full LLM context documentation
      --update          Update eunice to the latest version
      --debug           Enable debug output for API calls
  -h, --help            Print help
  -V, --version         Print version
```

## Webapp Mode

Start a web server interface:

```bash
eunice --webapp
# or with custom host/port
eunice --webapp --host 0.0.0.0 --port 8811
```

Opens at http://localhost:8811 by default.

## Configuration

No configuration files required. Eunice uses environment variables for API keys and smart defaults for everything else.

### Environment Variables

- `GEMINI_API_KEY` - Google AI Studio API key
- `OPENAI_API_KEY` - OpenAI API key
- `ANTHROPIC_API_KEY` - Anthropic API key
- `AZURE_OPENAI_ENDPOINT` - Azure OpenAI endpoint URL
- `AZURE_OPENAI_API_KEY` - Azure OpenAI API key
- `AZURE_OPENAI_API_VERSION` - Azure API version (optional)
- `OLLAMA_HOST` - Ollama server address (default: localhost:11434)
- `EUNICE_DEBUG` - Enable debug output (alternative to --debug flag)

### Prompt Files

Eunice auto-discovers prompt files in the current directory:
- prompt.txt, prompt.md
- instruction.txt, instruction.md
- instructions.txt, instructions.md

### API Key Rotation (Gemini)

For high-volume usage, place multiple Gemini API keys in `~/.eunice/gemini-api-keys.txt` (one per line). Eunice will rotate through them on rate limit errors.

## Version

v1.0.1

## License

MIT License

## Homepage

https://longrunningagents.com
